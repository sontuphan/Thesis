\chapter{Nền tảng lý thuyết}
\section{Bitcoin}
Các hình thức thương mại trên Internet ngày này hầu như đều dựa vào một tổ chức 
bên thứ ba đáng tin cậy để xử lý các hoạt động thanh toán điện tử. Tuy rằng sau 
nhiều năm phát triển, các tổ chức bên thứ ba này đều đã nâng cao mức độ tin cậy, 
an toàn nhưng đa số vẫn còn tồn tại những điểm yếu: không thể tránh khỏi những 
tranh chấp, phí trung gian, đòi hòi phải cung cấp các thông tin cá nhân... Và 
Bitcoin - hệ thống tiền điện tử ngang hàng (A Peer-to-Peer Electronic Cash System) 
được sinh ra để giải quyết các vấn đề trên \cite{BitcoinPaper}.
\subsection{Máy chủ nhãn thời gian - Timestamp Server}
Máy chủ nhãn thời gian hoạt động bằng cách lấy giá trị băm của block liền trước 
và thông tin của block hiện tại, cho qua hàm băm để được một giá trị băm mới. 
Giá trị băm sau khi được tính toán sẽ được công bố rộng rãi và giá trị băm này 
chứng minh rằng block tồn tại, các block được nối với nhau thành một chuỗi xác 
định.\\
\begin{figure}[h!]
\centering
\includegraphics[height=1.45in, keepaspectratio=true]{timestampserver.png}
\caption{Máy chủ nhãn thời gian}
\end{figure}\\
\subsection{Giao dịch - Transaction (trên Blockchain)}
Bitcoin tổ chức các giao dịch bằng cách xây dựng một chuỗi các chữ ký số. Một 
địa chỉ có chứa một lượng BTC được gọi là một chủ sở hữu, một chủ sở hữu 
chuyển một lượng BTC cho một chủ sở hữu khác - người thụ hưởng - bằng cách ký 
lên giá trị băm (hash), trong đó giá trị băm là kết quả sau khi đi qua hàm băm
của tổ hợp giá trị băm giao dịch trước với địa chỉ người thụ hưởng.\\
\begin{figure}[h!]
\centering
\includegraphics[height=2.45in, keepaspectratio=true]{transaction.png}
\caption{Giao dịch}
\end{figure}\\
\subsection{Proof-of-Work}
Proof-of-Work được hiểu là bằng chứng để chứng minh quá trình lao động, nó dùng 
để kiểm tra quá trình tạo ra kết quả hợp lệ là một quá trình ``lao động'' có 
sử dụng và tiêu tốn tài nguyên.\\\\
Proof-of-Work được sử dụng trong Bitcoin có cơ chế dựa trên hàm băm, ví dụ như 
SHA-256. Quá trình proof-of-work là quá trình đi tăng một con số - gọi là số 
$nonce$ - sao cho giá trị băm của số $nonce$ này cho kết quả đầu ra phải thỏa 
mãn tồn tại $n$ bit 0 ở vị trí đầu, với $n$ xác định và được gọi là số bit 0 
yêu cầu.
\subsection{Blockchain}
Blockchain được hình thành dựa trên sự kết hợp giữa máy chủ nhãn thời gian và 
proof-of-work. Blockchain là một chuỗi các block được kết nối một cách luận lý 
với nhau thông qua các mỗi quan hệ toán học và mật mã, các quan hệ này đảm bảo 
cho hệ thống luôn đúng đắn, không thể sửa và dễ dàng để kiểm tra. Block mới được 
sinh ra phải dựa trên quá trình proof-of-work.\\\\
Quá trình hình thành blockchain được bắt đầu bằng proof-of-work, các peer sẽ đi
tìm số $nonce$ sao cho sau khi cho qua hàm băm kết quả đạt được là một giá trị 
băm thỏa mãn số bit 0 yêu cầu. Số $nonce$ vừa được tìm ra sẽ được đưa và block
mới cùng với các thông tin khác như: thông tin các giao dịch, giá trị băm của 
block kề trước... Tiếp tục như vậy, các block mới được sinh ra và được kết nối 
với block cuối cùng của chuỗi.\\
\begin{figure}[h!]
\centering
\includegraphics[height=1.5in, keepaspectratio=true]{blockchain.png}
\caption{Blockchain}
\end{figure}\\
Vì hệ thống có tính phân tán nên trên toàn mạng sẽ có nhiều phiên bản của blockchain,
cũng chính vì thế để giải quyết tính đồng nhất, chỉ blockchain có độ dài lớn 
nhất mới được xem là blockchain hợp lệ. Đồng thời để kiểm soát được tốc độ sinh
block mới, hệ thống sẽ quy định một độ khó, nếu toàn mạng có tốc độ sinh block 
(số block được sinh ra trong một giờ đồng hồ) cao hơn mức quy định, độ khó sẽ tăng lên 
để điều chỉnh lại tốc độ của toàn mạng.
\subsection{Mạng - Network}
Mỗi thành viên (máy tính, phần cứng ASIC, thiết bị di dộng... ) khi tham gia vào quá 
trình tính toán của toàn mạng thì sẽ được xem như một node. Toàn mạng sẽ hiện thực hệ 
thống bằng cách thực hiện các bước như sau:
\begin{enumerate}
\item Một giao dịch mới được truyền đi cho tất cả các node (broadcast).
\item Mỗi node sẽ lựa chọn và thu thập các giao dịch để đưa vào block.
\item Mỗi node sẽ thực hiện proof-of-work, tìm ra số $nonce$.
\item Khi một node hoàn thành proof-of-work, node này sẽ đóng block và truyền 
đi toàn tất cả các node khác.
\item Các node khác sẽ kiểm tra thông tin của block nhận được (thông tin các 
giao dịch, thông tin proof-of-work...) và chấp nhận block này nếu tất cả 
các thông tin đều được kiểm tra chính xác.
\item Các node sẽ thể hiện sự chấp nhận của mình bằng cách thực hiện proof-of-work 
để sinh ra block mới block này sẽ được gắn vào liền sau block mà node đã chấp nhận 
(thêm giá trị băm của block trước mà node chấp nhận vào trong block mới sinh ra).
\end{enumerate}
Lưu ý, một giao dịch mới không nhất thiết phải được truyền đến tất cả các node. 
Chỉ cần việc truyền đến số node đủ nhiều để đảm bảo việc sẽ được đưa vào một block 
và được đóng trong blockchain với độ dài lớn nhất. Cũng như vậy đối với block, 
block không nhất thiết phải được truyền đến tất cả các node, khi một node nhận 
được một block kế block bị thiếu, bằng quá trình kiểm tra node có thể biết được 
và yêu cầu các node khác trong mạng gửi cho node này block bị thiếu sót.
\subsection{Phần thưởng khích lệ}
Trong tập các giao dịch được đóng trong một block sẽ luôn tồn tại một giao dịch 
đặc biệt, giao dịch khác với các giao dịch bình thường, nó không có người chủ 
sở hữu mà chỉ có người thụ hưởng. Điều này giải thích cách mà BTC mới được sinh 
ra, cứ mỗi block được tìm ra nhờ quá trình proof-of-work sẽ có một lượng BTC 
được sinh ra và chính là phần thưởng cho người tạo ra block, điều này đồng nghĩa 
địa chỉ người thụ hưởng chính là địa chỉ của người tạo ra block.\\\\
Ngoài ra, phần thưởng khích lệ khi tạo ra được một block còn bao gồm cả phí giao 
dịch từ các giao dịch đã được đóng trong block. Phí giao dịch thường rất nhỏ và
không đáng kể ở thời điểm hiện tại.
\subsection{Tổ chức lưu trữ thông tin giao dịch}
Đối với các node là các hệ thống máy tính lớn, khả năng lưu trữ và xử lý mạnh thì 
việc lưu một block với đầy đủ các thông tin không gặp nhiều vấn đề. Nhưng đối 
với các thiết bị di động hoặc các thiết bị khác với tài nguyên lưu trữ và xử lý 
tương đối hạn hẹp thì việc lưu một blockchain đầy đủ là khá khó khăn.\\\\
Cây Merkle là một cấu trúc tổ chức dữ liệu, trong đó giá trị của node cha sẽ 
là kết quả hàm băm tất cả các giá trị (nhãn hoặc dữ liệu) của nốt con. Các nốt 
không phải lá thì giá trị sẽ là nhãn - kết quả hàm băm, các nốt lá sẽ có giá trị 
là dữ liệu cần được tổ chức.\\\\
Bitcoin sử dụng cây Merkle để tổ chức các giao dịch, nốt cao nhất của cây được 
gọi là giá trị băm gốc (Root hash) và giá trị này sẽ được lưu vào block. Ở đây,
ta thấy việc thay đổi bất kỳ một giá trị nào trong cây cũng sẽ dẫn đến việc thay 
đổi giá trị băm gốc, vì thế giá trị băm gốc khi được lưu vào block nó có chức 
năng dùng để kiểm tra lại các giao dịch trong block đó là toàn vẹn hay không.\\
\begin{figure}[h!]
\centering
\includegraphics[height=2.25in, keepaspectratio=true]{merkletree.png}
\caption{Cây Merkle}
\end{figure}
\begin{figure}[h!]
\centering
\includegraphics[height=3.75in, keepaspectratio=true]{block.png}
\caption{Cấu trúc tổ chức giao dịch trong một block}
\end{figure}\\
Một node với tài nguyên hạn chế khi muốn lưu blockchain không nhất thiết phải 
lưu đầy đủ thông tin của từng block trong blockchain, thay vào đó node có thể 
lược bỏ các thông tin về giao dịch được đóng trong block và chỉ lưu giá trị băm 
gốc của các giao dịch này. Điều này làm giảm chi phí về lưu trữ nhưng vẫn đảm 
bảo được tính toàn vẹn, khi muốn xác minh bất kỳ giao dịch nào, node chỉ cần 
yêu cầu các giao dịch trong block và tính toán lại giá trị băm gốc, nếu giá trị 
băm nào giống với giá trị băm gốc được lưu nghĩa là các giao dịch hoàn toàn hợp 
lệ.
\section{Một số khái niệm về tài chính}
\subsection{Phiên giao dịch và các giá trị cơ bản}
Gọi $T$ là một mốc thời gian bất kỳ, $P$ là khoảng thời gian được chọn là một 
phiên giao dịch. Ta có thể nói một cách đơn giản là phiên giao dịch được mở tại 
thời điểm $T$ và được kết thúc tại thời điểm $T + P$.\\\\
Cụ thể, giả sử chọn mốc mở phiên là 9:00am và phiên giao dịch có thời hạn là 
30 phút, điều đó có nghĩa là kết thúc phiên giao dịch sẽ là 9:30am.\\\\
Các thông tin của một phiên giao dịch:
\begin{itemize}
\item Giá mở phiên: là giá bán của một giao dịch gần nhất sau thời điểm $T$. Ví 
dụ tại thời điểm 9:01am có một giao dịch bán 1 BTC là \$779 và trong khoảng thời 
gian 9:00am đến 9:01am không hề có bất kỳ giao dịch nào khác ngoại trừ giao dịch 
này, thì ta có thể nói giá mở phiên sẽ là \$779.
\item Giá đóng phiên: là giá bán của một giao dịch gần nhất trước thời điểm 
$T + P$.
\item Giá phiên cao nhất: là giá bán cao nhất của một giao dịch trong khoảng 
thời gian diễn ra phiên giao dịch, cụ thể là từ thời điểm $T$ đến thời điểm 
$T + P$. Ví dụ, trong khoảng thời gian 9:00am (thời điểm mở phiên) đến thời gian 
9:30am (thời điểm đóng phiên) có một giao dịch BTC với giá là \$801 và là giao 
dịch có giá trị cao nhất. Vậy ta có thể nó giá phiên cao nhất là \$801.
\item Giá phiên thấp nhất: là giá bán thấp nhất của một giao dịch trong khoảng 
thời gian diễn ra phiên giao dịch, cụ thể là từ thời điểm $T$ đến thời điểm $T + P$.
\item Lượng giao dịch: tổng giá trị USD được dùng để  mua/bán BTC trong một phiên 
giao dịch.
\item Trung bình giao dịch: giá trị USD trung bình của tất cả các giao dịch diễn 
ra trong khoảng thời gian một phiên giao dịch.
\end{itemize}
\subsection{Rate of Change}
Đại lượng đo sự khác nhau của giá tại phiên thứ $x$ so với $n$ phiên trước đó. 
Giá sử $P(x)$ là giá của phiên thứ $x$ thì:
\[ ROC_{n}(x)=\frac{P(x)-P(x-n)}{P(x-n)}\]
Nếu $ROC > 0$ thì giá thị trường đang có xu hướng đi lên (tăng giá).
Ngược lại, với $ROC < 0$ thì giá thị trường đang có xu hướng giảm xuống.
\subsection{Stochastic Oscillator}
Đại lượng dùng để đo xu hướng mua/bán của thị trường tại thời điểm phiên $x$ 
thông qua $n$ phiên trước đó. Giả sử:\\\\
\tab $L_{n} = $ giá phiên thấp nhất trong $n$ phiên\\
\tab $H_{n} = $ giá phiên cao nhất trong $n$ phiên\\
\tab $P(x) = $ giá của ngày $x$\\
\[\%K=\frac{P(x)-L_{n}}{H_{n}-L_{n}}\]
Nếu $ \%K $ nhỏ hơn 20 thì thị trường đang có xu hướng mua vào và nếu lớn hơn 
80 thì thị trường đang có xu hướng bán ra.


\section{Máy học}
\subsection{Khái niệm cơ bản}
\subsubsection{Máy học}
Máy học có hai cách định nghĩa chính và đang được chấp nhận phổ biến:
\begin{itemize}
  \item Theo Arthur Samuel: \textit{``Là một lĩnh vực nghiên cứu mà nó cung cấp cho
  máy tính khả năng học hỏi mà không cần lập trình một cách tường minh.''}
  \item Theo Tom Mitchell: \textit{``Một chương trình máy tính được chấp nhận
  là học hỏi được kinh nghiệm E bằng cách thực hiện một vài tác vụ T theo phép đo hiệu
  năng P, nếu và chỉ nếu việc thực thi các tác vụ trong T được đo bởi phép đo P
  đem lại kết quả là kinh nghiệm E được cải thiện.''}
\end{itemize}
\subsubsection{Học có giám sát - Supervised Learning}
Chúng ta được cho một tập dữ liệu đã biết với các đầu vào và đầu ra tương ứng
nhau. Ý tưởng là chúng ta sẽ đi tìm mối quan hệ giữa đầu vào và đầu ra, đó 
chính là học có giám sát.\\\\
Vấn đề của học có giám sát được phân loại thành hai
vấn đề chính là hồi quy - regression và phân lớp - classification. Trong vấn đề 
hồi quy, chúng ta sẽ cố gắng dự đoán kết quả đầu ra tiếp theo một cách liên tục, 
nghĩa là chúng ta đi tìm ra một hàm đầu ra liên tục tổng quát với biến là các 
đặc trưng đầu vào. Còn với vấn đề phân lớp, chúng ta thay vì cố gắng dự đoán kết
quả liên tục thì ta sẽ đi dự đoán chúng theo hướng rời rạc, hiểu theo một cách
khác là chúng ta đi tìm một phép phân loại rời rạc cho các biến đầu ra với các 
biến đầu vào.
\subsubsection{Học không giám sát - Unsupervised Learning}
Học không giám sát cho phép chúng ta tiếp cận các vấn đề mà ta chưa hề hoặc biết
rất ít kết quả của chúng ta sẽ trông như thế nào. Chúng ta có thể xây dựng cấu
trúc của dữ liệu mà không cần thiết phải biết mối quan hệ của các biến đó.\\\\
Chúng ta thực hiện việc này dựa trên ý tưởng gom cụm dữ liệu bằng cách xem xét
mối quan hệ giữa các đặc trưng của dữ liệu. Các hướng tiếp cận dựa trên nhưng 
phương pháp như vậy thường được gọi là gom cụm - clustering.

\subsection{Thông số đánh giá}
Có ba tham số cơ bản dùng để xem xét và đánh giá giải thuật trong Máy học.
Gọi:
\begin{itemize}
\item True positive là $TP$
\item False positive là $FP$
\item True negative là $TN$
\item False negative là $FN$
\end{itemize}
Thì:\\
\[
  Accuracy = \frac{TP+TN}{TP+FP+TN+FN}
\]
\[
  Precision = \frac{TP}{TP+FP}
\]
\[
  Recall = \frac{TP}{TP+FN}
\]\\
\begin{figure}[h!]
\centering
\includegraphics[height=4.3in, keepaspectratio=true]{precision_recall.png}
\caption{Thông số đánh giá}
\end{figure}\\
\subsection{Mạng neural - Neural Network}
Học sâu - Deep Learning - là một nhánh của Máy học, đại diện cho hướng tiếp 
cận gần với cái nhìn thực tế, học nhiều cấp và học từ bản chất dữ liệu. Học 
sâu thường giải quyết rất tốt với các loại dữ liệu mang tính ``con người'' 
như hình ảnh, âm thanh ... Để có được những tính chất này, Học sâu đã đưa ra 
các giải thuật mạng neural với cấu tạo nhiều lớp, mỗi lớp lại được cấu tạo từ 
nhiều phần tử nhỏ hơn. Mỗi phần tử bên trong đi giải quyết các phép toán rất 
đơn giản, nhưng khi được ghép nối lại thành một mạng neural hoàn chỉnh chúng có 
thể giải quyết các bài toán phức tạp hơn rất nhiều, điều này hoàn toàn tương tự 
với các hoạt động của bộ não người. \cite{NeuralNetworksandDeepLearning} 
\subsubsection{Cấu trúc một Perceptron}
Một perceptron sẽ có các input $x_1, x_2, ...$ và output sẽ là một giá trị 
nhị phân.\\
\begin{figure}[h!]
\centering
\includegraphics[height=1.5in, keepaspectratio=true]{perceptron.png}
\caption{Perceptron}
\end{figure}\\
Một ví dụ đơn giản dựa vào hình trên, ta thấy perceptron này có 3 input là 
$x_1, x_2, x_3$ , giả sử đi kèm với mỗi input sẽ có một giá trị trọng 
số $w_1, w_2, w_3$. Output được định nghĩa là 0 và 1, nhận giá trị 0 
khi $\sum_j w_j x_j$ nhỏ hơn giá trị ngưỡng và 1 khi lớn gơn giá trị ngưỡng.\\\\
Biểu diễn đại số:\\
\[
  output = 
  \bigg\{
    _{0 \quad if \, \sum_j w_j x_j \, \leq \, threshold}
    ^{1 \quad if \, \sum_j w_j x_j \, > \, threshold}
\]
Các hàm số như trên được gọi là activation function, có nhiều loại activation
 function khác nhau như: $sigmoid , tang ...$ 

\subsubsection{Multilayer Neural Network}
Hiển nhiên, một perceptron không thể mô phỏng nên được một bộ não người, để 
có thể đưa ra một quyết định tương tự như bộ não người các perceptron này cần 
được kết nối với nhau thành một mạng lưới - Multilayer Neural Network.\\
\begin{figure}[h!]
\centering
\includegraphics[height=2in, keepaspectratio=true]{multilayerneuralnetwork.png}
\caption{MNN}
\end{figure}\\
Multilayer Neural Network được cấu thành bằng cách sắp xếp các perceptron thành 
từng lớp. Các perceptron ở mỗi lớp sẽ kết nối với tất cả các perceptron ở các 
lớp liền kề, cột những perceptron đầu tiên được gọi là input layer, chúng có 
chức năng tiếp nhận các input để cho ra các output. Các output ở lớp trước sẽ chính là 
input cho các perceptron ở lớp tiếp theo. Các perceptron ở lớp cuối cùng được gọi là 
output layer, trong trường hợp này đặc biệt chỉ có duy nhất một perceptron. Còn 
lại các lớp perceptron khác được gọi là hidden layer.\\\\
Giả sử input của perceptron là $x_1, x_2, ...$ tương ứng là đó là các trọng 
số $w_1, w_2, ...$. Thêm vào đó định nghĩa về bias, ở đây bias là một giá trị 
đại diện độ lệch của từng perceptron và được ký hiệu $b_1, b_2, ...$. Ta có biểu diễn của activation 
function:\\
\[
  output = 
  \bigg\{
    _{0 \quad if \, \sum_j w_j x_j + b_i\, \leq \, 0}
    ^{1 \quad if \, \sum_j w_j x_j + b_i\, > \, 1}
\]
Ví dụ:\\
\begin{figure}[h!]
\centering
\includegraphics[height=1in, keepaspectratio=true]{exmln.png}
\caption{Ví dụ perceptron với giá trị bias}
\end{figure}\\
Ta có $w_1=w_2=-2$ và $b=3$, khi đó nếu input $x_1=1,\, x_2=0$ suy ra $ 
w_1*x_1+w_2*x_2+b=(-2)*1+(-2)*0+3=1$, ta có thể chọn $threshold=0$ vì $1>0$
nên $output=1$.

\subsubsection{Sigmoid Function - Hàm Sigmoid}
Với dạng activation function được định nghĩa ở trên, giá trị của activation 
function gần như không có giới hạn. Vậy tại sao việc không có giới hạn lại 
cần được quan tâm. Trong một trường hợp cụ thể, với việc sử dụng activation 
function như trên có thể dẫn đến trường hợp đầu ra của một perceptron sẽ nhận 
giá trị rất lớn - giả sử là 1000, những một perceptron khác sẽ nhận giá trị rất 
bé - giả sử 0.001. Vì thế khi đến lớp tiếp theo thì gần như perceptron cho kết 
quả đầu ra là giá trị bé sẽ mất đi độ ảnh hưởng và làm mất cân đối cho toàn mạng.\\\\
Do đó để giới hạn giá trị của activation function chúng ta sẽ sử dụng hàm sigmoid. 
Sigmoid function được định nghĩa như sau:\\
\[
  \sigma(z)=\frac{1}{1+e^{-z}}
\]
Áp dụng Sigmoid function vào activation function ta có activation function dạng
sigmoid và khi đó activation function của chúng ta sẽ có dạng:\\
\[
  \frac{1}{1+exp(-\sum_j w_j x_j -b)}
\]
Lúc này ta có một activation function có giá trị được giới hạn trong khoảng 
từ 0 đến 1. Nhưng chú ý, giá trị của activation function là liên tục, để rời 
rạc hóa giá trị của activation function ta có thể sử dụng một phương pháp 
quen thuộc - sử dụng threshold. Điển hình ta chọn threshold = 0.5, nếu lớn hơn 
thì activation function sẽ nhận 1 và ngược lại sẽ nhận 0.\\
\begin{figure}[h!]
\centering
\includegraphics[height=3.85in, keepaspectratio=true]{sigmoid.png}
\caption{Đồ thị hàm sigmoid}
\end{figure}\\
\begin{figure}[h!]
\centering
\includegraphics[height=3.5in, keepaspectratio=true]{step.png}
\caption{Đồ thị rời rác hóa hàm sigmoid}
\end{figure}\\

\subsubsection{Giải thuật lan truyền ngược}
Sau khi đã có xây dựng thành công một mô hình Multilayer Neural Network, công 
việc cuối cùng là cung cấp khả năng tự học hỏi từ đó để bản thân mạng có thể 
tự xây dựng mô hình và đưa ra các quyết định cụ thể.\\\\
Cụ thể, khi nhìn lại một Multilayer Neural Network với activation function là 
sigmoid function thì các tham sô $w, b$ là chưa biết và việc cung cấp khả năng 
tự học hỏi chính là cung cấp một giải thuật giúp mạng tìm được các tham số 
$w, b$ với một tập kinh nghiệm - hay tập huấn luyện - ${x, y}$ cụ thể, trong 
đó $x$ là input và $y$ là output tương ứng với từng bộ $x$. Giải thuật lan truyền 
ngược là một trong nhưng giải thuật chúng ta cần tìm.\\\\
Trước tiên chúng ta cần đi qua một số ký hiệu:
\begin{itemize}
\item $w$ là vector của các giá trị trọng số\\ 
\[ w =
\begin{bmatrix}
w_1\\
\vdots\\
w_n
\end{bmatrix}
\]
\item $b$ là vector của các giá trị bias\\ 
\[ b =
\begin{bmatrix}
b_1\\
\vdots\\
b_m
\end{bmatrix}
\]
\item $\sigma$ là sigmoid function
\item $a(\sigma)$ là activation function có dạng sigmoid
\end{itemize}
Biểu diễn activation function:\\
\begin{figure}[h!]
\centering
\includegraphics[height=2in, keepaspectratio=true]{exw.png}
\caption{Weight Notation example}
\end{figure}\\
Ví dụ như hình trên, trọng số xuất phát từ perceptron thứ 4 thuộc layer thứ 
2 và kết thúc tại perceptron thứ 2 thuộc layer thứ 3 được ký hiệu là 
$w_{24}^3$.\\\\
Tương tự như vậy với bias và activation function của perceptron thứ j thuộc layer 
thứ l của mạng sẽ được kí hiệu thứ tự là $b_j^\ell,\,a_j^\ell$. Ví dụ, bias của perceptron 
thứ 3 thuộc layer thứ 2 sẽ là $b_3^2$ và activation function của perceptron thứ 
1 thuộc layer thứ 3 sẽ là $a_1^3$.\\
\begin{figure}[h!]
\centering
\includegraphics[height=2in, keepaspectratio=true]{exb.png}
\caption{Bias Notation example}
\end{figure}\\
Lúc này ta có biểu diễn toán học đầy đủ của activation function:\\
\[
  a_j^\ell=\sigma(\sum_k w_{jk}^\ell a_k^{\ell-1} + b_j^\ell)
\]
Với ký hiệu vector ta có thể tổng quát phát biểu với dạng:\\
\[
  a^\ell=\sigma(w^\ell a^{\ell-1} + b^\ell)
\]
\textbf{Cost function:} Trước khi đi vào hiểu được giải thuật lan truyền ngược 
có thể làm gì, chúng ta cần phải biết một định nghĩa cost function. Vậy cost 
function là gì? Đúng theo tên của hàm, nó dùng để đo lường chi phí của thuật toán. Chi tiết:\\
\[
  C=\frac{1}{2n}\sum_x\|y(x)-a^L(x)\|^2
\]
Ta có thể thấy, dạng hàm số trên hết sức quen thuộc với định nghĩa độ lệch chuẩn 
trong xác suất thống kê nhưng đã được biến đổi một chút. Thay vì giá trị kỳ vọng 
và các điểm xác suất, cost function sử dụng giá trị thực tế $y$ của tập dữ liệu 
và giá trị $y=a$ là giá trị $y$ tính toán được từ $x$ với $w$ và $b$. Vậy ta 
có thể hiểu được, cost function tính toán độ sai lệch của giá trị $a$ so với 
$y$ kỳ vọng thực tế. Do đó, cost function càng nhỏ thì biểu diễn giá trị của 
MNN sẽ càng gần với thực tế.\\\\
Để tìm được giá trị cực tiểu cho cost function ta sẽ thực hiện vòng lặp:\\
\[
  w_{ij}^{(\ell)}:=w_{ij}^{(\ell)}-\eta\frac{\sigma}{\sigma w_{ij}^{(\ell)}}C(w,b)
\]
\[
  b_i^{(\ell)}:=b_i^{(\ell)}-\eta\frac{\sigma}{\sigma b_i^{(\ell)}}C(w,b)
\]

Trong đó $\eta$ là tỉ lệ học - learning rate, việc hội tụ về giá trị cực tiểu với 
tốc độ và độ chính xác phụ thuộc vào tỉ lệ này.\\\\
Vậy, đi qua một quá trình tìm hiểu về MNN, ta có thể hiểu được việc học hỏi 
kinh nghiệm của mạng cốt lõi vẫn là việc tìm ra bộ $w$ và $b$ 
tương ứng với ${x, y}$ của bộ dữ liệu luyện tập, và để tìm ra được $w$ và $b$ 
ta có thể sử dụng giải thuật lan truyền ngược.